---
title: "Homework 6"
output: html_document
author: Akshay Gona
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Problem 1. Warm up: Log-Odds, Odds and Probability <small>5 points; 1 point each</small>

a. Convert a log-odds of 1.75 to probability.

```{r}
log_odds <- 1.75
probability <- exp(log_odds) / (1 + exp(log_odds))
probability
```

***

0.8519528

***

b. Convert probability of 0.85 to odds.

```{r}
probability <- 0.85
odds <- probability / (1 - probability)
odds
```


***

5.666667

***

c. Event A has a probability of 0.7 and the odds ratio of A to B is 1.45. Calculate the probability of event B.

```{r}
odds_ratio <- 1.45
p_B <- 7 / 11.35
#7 = p_A
#11.35 is 1-p_A = 1.45(P_B/(1-p_B))
print(p_B)
```


***
0.6167401
***

d. You roll a single 6 sided die. What are the odds you get a number divisible by 3?

```{r}
total_outcomes <- 6
divisible_by_3_outcomes <- 2
odds_divisible_by_3 <- divisible_by_3_outcomes / (total_outcomes - divisible_by_3_outcomes)
print(paste("Odds of getting a number divisible by 3:", odds_divisible_by_3))
```

***

0.5

***

e. The odds ratio comparing event A to B is 9 and the risk ratio is 3. What is $Pr(A)$? *Hint: let $Pr(A)=a$ and $Pr(B)=b$, and write out the odds ratio and risk ratio as equations. 
```{r}
odds_ratio_eq <- function(a, b) {
  return ((a / (1 - a)) / (b / (1 - b)) - 9)
}
risk_ratio_eq <- function(a, b) {
  return (a / b - 3)
}
solve_equations <- function() {
  b <- 1/4
  a <- 3 * b
  return(a)
}
Pr_A <- solve_equations()
Pr_A
```

*** 

0.75

***



## Problem 2. Interpreting logistic regression <small>6pts; 2 pts each</small>

Suppose we collect data for a group of students in a statistics class with independent variables $X_{1}=\text{hours studied}$, $X_{2}=\text{GPA}$, and binary response variable
$$
Y= \begin{cases} 1 &\mbox{ if student received an A} \\
  0 &\mbox{ otherwise. }
  \end{cases}
$$
Suppose that we fit a logistic regression model to the data, predicting $Y$ from $X_1$ and $X_2$ (and an intercept term) and produce estimated coefficients $\hat{\beta}_{0}=-6, \hat{\beta}_{1}=0.05, \hat{\beta}_{2}=1$.

### Part a) Logistic regression and probability

According to our fitted model, what is the probability that a student receives an A if they study for $40$ hours and have a GPA of $3.5$?

```{r}
b0 <- -6
b1 <- 0.05
b2 <- 1

X1 <- 40
X2 <- 3.5

probA1 <- 1 / (1 + exp(-(b0 + b1 * X1 + b2 * X2)))
probA1
```

### Part b) Interpreting coefficients
According to our fitted model, an additional hour spent studying is associated with *how much* of an increase in the log odds of receiving an A?

```{r}
b1
```

### Part c) "Inverting" logistic regression probabilities
According to our fitted model, how many hours would the student in Part (a) need to study to have a $50\%$ chance of getting an A in the class?
That is, keeping GPA fixed at $3.5$, how many hours of study are needed so that the probability of an A is $50\%$?
If you aren't up for the math, feel free to find an approximate solution via guess-and-check in R.

***

To determine the amount of study time required for a student to have a 50% chance of earning an A in the class, we need to find the value of X_1 in the logistic function when the probability is 0.5, with X_2 set at 3.5. Running this calculation in R gives us the result that X_1 would be 50 in this scenario.

***

```{r}
X_1 <- uniroot(function(x) 1 / (1 + exp(-(b0 + b1 * x + b2 * X2))) - 0.5, interval = c(0, 100))$root
X_1
```



## Problem 3. Palmer Penguins Part I  <small>9pts; 3 pts each</small>

The Palmer Penguin dataset (https://allisonhorst.github.io/palmerpenguins/) consists of 344 observations of penguins belonging to 3 penguin species across the islands in the Palmer Archipeligo in Antarctica. We will build a logistic model attempting to classify the penguins based on physical characteristics. For each penguin we've recorded: 

* `species` - the species, either "Gentoo", "Adelie" or "Chinstrap"
* `island` - which of three islands the Penguin was observed (Biscoe, Dream or Torgersen)
* `bill_length_mm` - the length of the bill in mm
* `bill_depth_mm` - the depth of the bill (vertical thickness of the closed bill)
* `filler_length_mm` - length of their cute flippers
* `body_mass_g` - the body mass in grams
* `sex` - female, male or NA (unknown)
* `year` - The year of the observation: 2007, 2008 or 2009

First you need to download the library. Run this chunk of code once.
```{r, eval=FALSE, echo=FALSE}
#Run this code once to install the library
install.packages("palmerpenguins")
```

Then load the library and the penguin dataset. Note: Your RMD won't knit until you run the above chunk.
```{r}
library(palmerpenguins)
```

### a) Adelie penguins based on island

We are going to try to classify penguins as **Adelie** or **not Adelie**. So create a new variable called `Adelie` which will be 1 or 0 based on whether the penguin species is Adelie

```{r}
penguins <- palmerpenguins::penguins
penguins$Adelie <- ifelse(penguins$species == "Adelie", 1, 0)
```

Perform some analysis looking at each of the 3 islands - create a 2 way table between `island` and the `Adelie` variable. Look at the proportions conditioned on island. What proportion of observations on each island were Adelie?

```{r}
table_island_adelie <- table(penguins$island, penguins$Adelie)
prop_adelie_island <- prop.table(table_island_adelie, margin = 1)
prop_adelie_island
```

***
Biscoe: 26.19%
Dream: 45.16%
Torgersen: 100%

***

### b) Adelie Penguins on Dream

Find the (i) probability, (ii) odds and (iii) log-odds that a randomly selected penguin from Dream is an Adelie penguin?

```{r}
# b) Probability, odds, and log-odds of a penguin from Dream being Adelie
p_dream_adelie <- prop_adelie_island["Dream", "1"]
p_dream_adelie
odds_dream_adelie <- p_dream_adelie / (1 - p_dream_adelie)
odds_dream_adelie
log_odds_dream_adelie <- log(odds_dream_adelie)
log_odds_dream_adelie
```

***
i) 0.4516129
ii) 0.8235294
iii) -0.194156

***

### c) An island-based classifier

Now fit a logistic model predicting whether a penguin is Adelie based on island.
Interpret the intercept and the coefficient of the `islandDream` variable. Use this model to predict the probability that a penguin from Dream is Adelie.

```{r}
model <- glm(Adelie ~ island, data = penguins, family = binomial)
summary(model)
p_dream_adelie_predicted <- predict(model, newdata = data.frame(island = "Dream"), type = "response")
p_dream_adelie_predicted
```

***
0.4516129
***


## Problem 4. Penguins Part II <small>10pts; 2 pts each</small>

In this problem we will work once again with the Palmer Penguin dataset. We will work with a subset by taking out all missing values. After you have installed the package and loaded the library, uncomment the line below.
```{r}
penguins.complete <- penguins[complete.cases(penguins),]
```

### a) Predicting Palmer Penguins with quantitative Predictors

Now use the two bill measurements (`bill_length_mm` and `bill_depth_mm` as predictors in a new logistic model. Suppose a penguin with a bill length of 53.1 and a bill depth of 22.7 is observed. What is the model's probability that the penguin is an Adelie penguin?

```{r}
#your code goes here
penguins.complete <- penguins[complete.cases(penguins),]
model <- glm(Adelie ~ bill_length_mm + bill_depth_mm, data = penguins.complete, family = "binomial")
npngn <- data.frame(bill_length_mm = 53.1, bill_depth_mm = 22.7)
prob_adelie <- predict(model, newdata = npngn, type = "response")
prob_adelie
summary(model)
```

***

The model's probability the penguin is an Adelie penguin is 7.9%.

***

### b) Interpreting coefficients

Are longer bills associated with an increased or decreased likelihood that a penguin is an Adelie penguin?

***
As bill length increases, the log odds of te penguin being an adelie decreases.coefficient of bill_length_mm is -2.2099
***

### c) A full classifier

Fit a logistic model to predict whether a penguin is a **Chinstrap** penguin using all four of the biological measurements (`bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, and `body_mass_g`). 

```{r}
model1 <- glm(species == "Chinstrap" ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data = penguins.complete, family = "binomial")
summary(model1)
```

Which of the predictors are significant?

***

Bill_length_mm and body_mass_g are significant, pvals less than 0.05.

***

### d) Assessing the model
Suppose you will predict that a penguin is a Chinstrap if the estimated $\hat{y}=\sigma(\hat{z})>0.5$. When predicting using this threshold, what is the type 1 error rate of your predictor on the dataset? What is power of the predictor on the dataset? 
*Hint: you will want to compare the predicted $\hat{y}$ values to the actual $y$ values. The `table` command can produce a 2x2 confusion matrix to help you answer this question.*


```{r}
predicted_probabilities <- predict(model1, type = "response")
threshold <- 0.5
predicted_classes <- ifelse(predicted_probabilities > threshold, "Chinstrap", "Not Chinstrap")
actual_classes <- ifelse(penguins.complete$species == "Chinstrap", "Chinstrap", "Not Chinstrap")
confusion_matrix <- table(predicted_classes, actual_classes)
confusion_matrix
type_one <- sum(predicted_classes == "Chinstrap" & actual_classes == "Not Chinstrap") / sum(actual_classes == "Not Chinstrap")
power <- sum(predicted_classes == "Chinstrap" & actual_classes == "Chinstrap") / sum(actual_classes == "Chinstrap")
type_one
power
```

***

Type 1 error is ~0.003, and power is around 0.96.

***


### e) Adjusting the Type 1 error rate

Now modify your threshold from 0.5 to some other threshold with the goal of achieving the highest power possible while keeping the type 1 error rate  below 0.05. What threshold would you use? What is the type 1 error rate and power of this new classifier?

```{r}
predicted_probabilities <- predict(model1, type = "response")
threshold <- 0.03
predicted_classes <- ifelse(predicted_probabilities > threshold, "Chinstrap", "Not Chinstrap")
actual_classes <- ifelse(penguins.complete$species == "Chinstrap", "Chinstrap", "Not Chinstrap")
confusion_matrix <- table(predicted_classes, actual_classes)
confusion_matrix
type_one <- sum(predicted_classes == "Chinstrap" & actual_classes == "Not Chinstrap") / sum(actual_classes == "Not Chinstrap")
power <- sum(predicted_classes == "Chinstrap" & actual_classes == "Chinstrap") / sum(actual_classes == "Chinstrap")
type_one
power
```

***

I would use a threshold of 0.03, and the type one error is now 0.05 and the power is 1.

***
